import os
import tensorflow as tf
from tensorflow import keras

# -----------------------------------------------------------------
# 1. 경로 및 하이퍼파라미터 설정
# -----------------------------------------------------------------
TRAIN_TFRECORD = r"C:\malware_sample\tfrecord\train_Adaptive.tfrecord"  # 학습용 TFRecord 파일 경로
VAL_TFRECORD   = r"C:\malware_sample\tfrecord\val_Adaptive.tfrecord"    # 검증용 TFRecord 파일 경로

BATCH_SIZE     = 16
EPOCHS         = 20            # 에폭 수 조절
IMG_HEIGHT     = 224
IMG_WIDTH      = 224
CHANNELS       = 1            # 최종 입력은 그레이스케일(1채널)
SAVE_FILENAME  = "cnn_model_2class_Adaptive_test1.h5"  # 저장될 모델 파일 이름

# -----------------------------------------------------------------
# 2. TFRecord 파싱 함수
# -----------------------------------------------------------------
def parse_tfrecord_fn(record):
    """
    TFRecord Example에서 이미지와 라벨을 추출한 후,
    - 이미지: BMP 파일 바이너리 → 3채널(RGB)로 디코딩 → 그레이스케일 변환 → 리사이즈 및 표준화
    - 라벨: int64 (0 또는 1)
    
    최종적으로 (IMG_HEIGHT, IMG_WIDTH, 1) 텐서와 라벨을 반환.
    """
    features = {
        "image/encoded": tf.io.FixedLenFeature([], tf.string),
        "image/hashval": tf.io.FixedLenFeature([], tf.string),
        "image/class/label": tf.io.FixedLenFeature([], tf.int64),
    }
    parsed = tf.io.parse_single_example(record, features)
    img_data = parsed["image/encoded"]
    label = parsed["image/class/label"]

    # BMP 파일은 1채널 디코딩을 직접 지원하지 않으므로,
    # 항상 3채널로 디코딩한 후, RGB -> 그레이스케일 변환
    image = tf.io.decode_bmp(img_data, channels=3)
    image = tf.image.rgb_to_grayscale(image)  # 결과: (H, W, 1)

    # CNN 입력에 맞춰 리사이즈
    image = tf.image.resize(image, [IMG_HEIGHT, IMG_WIDTH])
    # 표준화: per-image normalization (평균 0, 분산 1)
    image = tf.image.per_image_standardization(image)

    return image, label

# -----------------------------------------------------------------
# 3. tf.data.Dataset 생성 함수
# -----------------------------------------------------------------
def create_dataset(tfrecord_path, batch_size, shuffle=True):
    """
    주어진 TFRecord 경로에서 (image, label) 쌍의 배치를 반환하는 Dataset 생성
    """
    dataset = tf.data.TFRecordDataset(tfrecord_path)
    dataset = dataset.map(parse_tfrecord_fn, num_parallel_calls=tf.data.AUTOTUNE)
    if shuffle:
        dataset = dataset.shuffle(buffer_size=10000)
    dataset = dataset.batch(batch_size)
    dataset = dataset.prefetch(tf.data.AUTOTUNE)
    return dataset

# -----------------------------------------------------------------
# 4. CNN 모델 정의 (2-class)
# -----------------------------------------------------------------
def build_cnn_model():
    """
    5단계의 Conv+Pooling 및 3단계의 FC 레이어를 사용한 CNN 모델.
    최종 출력은 2개 노드(softmax)로 2클래스 분류.
    입력 shape: (IMG_HEIGHT, IMG_WIDTH, CHANNELS) = (224, 224, 1)
    """
    model = keras.Sequential([
        # Block 1: (224,224,1) -> (112,112,32)
        keras.layers.Conv2D(32, (3,3), padding='same', activation='relu', input_shape=(IMG_HEIGHT, IMG_WIDTH, CHANNELS)),
        keras.layers.BatchNormalization(),
        keras.layers.Conv2D(32, (3,3), padding='same', activation='relu'),
        keras.layers.BatchNormalization(),
        keras.layers.MaxPooling2D(pool_size=(2,2)),
        
        # Block 2: (112,112,32) -> (56,56,64)
        keras.layers.Conv2D(64, (3,3), padding='same', activation='relu'),
        keras.layers.BatchNormalization(),
        keras.layers.Conv2D(64, (3,3), padding='same', activation='relu'),
        keras.layers.BatchNormalization(),
        keras.layers.MaxPooling2D(pool_size=(2,2)),
        
        # Block 3: (56,56,64) -> (28,28,128)
        keras.layers.Conv2D(128, (3,3), padding='same', activation='relu'),
        keras.layers.BatchNormalization(),
        keras.layers.Conv2D(128, (3,3), padding='same', activation='relu'),
        keras.layers.BatchNormalization(),
        keras.layers.MaxPooling2D(pool_size=(2,2)),
        
        # Block 4: (28,28,128) -> (14,14,256)
        keras.layers.Conv2D(256, (3,3), padding='same', activation='relu'),
        keras.layers.BatchNormalization(),
        keras.layers.Conv2D(256, (3,3), padding='same', activation='relu'),
        keras.layers.BatchNormalization(),
        keras.layers.MaxPooling2D(pool_size=(2,2)),
        
        # Flatten and Fully Connected Layers
        keras.layers.Flatten(),
        keras.layers.Dense(512, activation='relu'),
        keras.layers.BatchNormalization(),
        keras.layers.Dropout(0.3),
        keras.layers.Dense(128, activation='relu'),
        keras.layers.BatchNormalization(),
        # 최종 출력: 2클래스
        keras.layers.Dense(2, activation='softmax')
    ])
    return model

# -----------------------------------------------------------------
# 5. 학습 함수
# -----------------------------------------------------------------
def train_cnn():
    # TFRecord 파일로부터 Dataset 생성
    train_ds = create_dataset(TRAIN_TFRECORD, BATCH_SIZE, shuffle=True)
    val_ds = create_dataset(VAL_TFRECORD, BATCH_SIZE, shuffle=False)

    # 모델 생성 및 컴파일
    model = build_cnn_model()
    model.compile(
        optimizer=keras.optimizers.Adam(learning_rate=1e-4),
        loss='sparse_categorical_crossentropy',  # 라벨이 int (0 또는 1)일 경우 사용
        metrics=['accuracy']
    )

    # 모델 학습
    model.fit(
        train_ds,
        validation_data=val_ds,
        epochs=EPOCHS
    )

    # 모델 저장: 현재 폴더의 하위 디렉터리 "h5"에 저장
    save_dir = os.path.join(os.getcwd(), "h5")
    os.makedirs(save_dir, exist_ok=True)
    save_path = os.path.join(save_dir, SAVE_FILENAME)
    model.save(save_path)
    print("Model saved to:", save_path)

# -----------------------------------------------------------------
# 6. 실행부
# -----------------------------------------------------------------
if __name__ == "__main__":
    train_cnn()
